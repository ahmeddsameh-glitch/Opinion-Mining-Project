{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98510e74",
   "metadata": {},
   "source": [
    "# Subjectivity Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added490",
   "metadata": {},
   "source": [
    "### 1. Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file = '../../data/test_sample.csv'\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "df\n",
    "df[\"lemmatized\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315083b",
   "metadata": {},
   "source": [
    "### 2. Subjectivity Detection Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/mca/Opinion-Mining-Project/src')\n",
    "\n",
    "from tokenization_utils import tokenize_sentence \n",
    "from preprocess_text import better_sentence_splitter\n",
    "# from training_model import get_obj_docs_extra,get_subj_docs_extra\n",
    "#nltk.corpus.subjectivity is a built-in NLTK corpus that contains a dataset of subjective and objective sentences extracted from movie reviews. \n",
    "from nltk.corpus import subjectivity\n",
    "# NaiveBayesClassifier is a simple probabilistic classifier from NLTK that we use to train on those labeled sentences so it learns to classify new sentences as subjective or objective.\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "#sent_tokenize is used to split raw text (big sentences) into sentences before classifying each one.\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('subjectivity')\n",
    "# We create subj_docs and obj_docs as training data for the classifier.\n",
    "# The classifier uses this data to learn how to tell if a sentence is an opinion or a fact.\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')] \n",
    "\n",
    "# - Pair features with labels.\n",
    "additional_subj_docs = [\n",
    "    (['brand', 'guy', 'rock', 'keep'], 'subj'),\n",
    "    (['thanks', 'brand', 'quick', 'support'], 'subj'),\n",
    "    (['awesome', 'job'], 'subj'),\n",
    "    (['love', 'this'], 'subj'),\n",
    "    (['great', 'service'], 'subj'),\n",
    "    (['really', 'liked', 'it'], 'subj'),\n",
    "    (['highly', 'recommended'], 'subj'),\n",
    "    (['fantastic', 'work'], 'subj'),\n",
    "    (['well', 'done'], 'subj'),\n",
    "    (['perfect', 'experience'], 'subj')\n",
    "]\n",
    "additional_subj_docs += [\n",
    "    (['excellent', 'product'], 'subj'),\n",
    "    (['very', 'happy', 'with', 'this'], 'subj'),\n",
    "    (['not', 'what', 'I', 'expected'], 'subj'),\n",
    "    (['disappointed', 'with', 'service'], 'subj'),\n",
    "    (['highly', 'suggest', 'to', 'try'], 'subj'),\n",
    "    (['would', 'buy', 'again'], 'subj'),\n",
    "    (['terrible', 'quality'], 'subj'),\n",
    "    (['best', 'purchase', 'ever'], 'subj'),\n",
    "    (['not', 'recommend'], 'subj'),\n",
    "    (['loved', 'it'], 'subj'),\n",
    "]\n",
    "subj_docs_extended = subj_docs + additional_subj_docs\n",
    "# Feature extractor example: presence of words\n",
    "def extract_features(words):\n",
    "#extract_features(['The', 'movie', 'was', 'Great'])\n",
    "# {\n",
    "#   'the': True,\n",
    "#   'movie': True,\n",
    "#   'was': True,\n",
    "#   'great': True\n",
    "# }\n",
    "    return {word.lower(): True for word in words}\n",
    "# Prepare training data\n",
    "# - Combine all subjective and objective labeled sentences.\n",
    "\n",
    "# - Convert each sentence into a feature dictionary using extract_features.\n",
    "# Combine with original subjective documents\n",
    "# - Store all pairs in train for classifier training.\n",
    "train = [(extract_features(doc), label) for doc, label in subj_docs_extended + obj_docs]\n",
    "# Train classifier\n",
    "classifier = NaiveBayesClassifier.train(train)\n",
    "all_labels = []\n",
    "for index, row in df.iterrows():\n",
    "    lemmatized_text = row['lemmatized']\n",
    "    print(\"l\",lemmatized_text)\n",
    "    sentences = better_sentence_splitter(lemmatized_text)\n",
    "    print(\"sentences : \",sentences)\n",
    "    sentence_labels = []\n",
    "    for sentence in sentences:\n",
    "        words = tokenize_sentence(sentence)   # word tokenizer\n",
    "        features = extract_features(words)\n",
    "        print(\"after extracting features : \", features)\n",
    "        label = classifier.classify(features)\n",
    "        sentence_labels.append(label)\n",
    "        print(f\"{label.upper():>4} â†’ {sentence}\")\n",
    "    all_labels.append(sentence_labels)\n",
    "df['sentence_subjectivity'] = all_labels\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce7538",
   "metadata": {},
   "source": [
    "### 3. Change to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39e6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/test_sample.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
