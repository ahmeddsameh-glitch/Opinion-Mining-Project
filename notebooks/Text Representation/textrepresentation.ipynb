{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52c6e9a",
   "metadata": {},
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f31b4",
   "metadata": {},
   "source": [
    "### 1. Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337a33b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        paula may bitch ill never butch br br hilariou...\n",
       "1        many people say show kid hm kid approximately ...\n",
       "2        well write tale make batman sitcom actually re...\n",
       "3        think movie absolutely beautiful im not refer ...\n",
       "4        film outstanding despite nc17 rating disturb s...\n",
       "                               ...                        \n",
       "59995                                      nothing special\n",
       "59996    avoid one terrible movie excite pointless murd...\n",
       "59997    production quite surprise absolutely love obsc...\n",
       "59998    decent movie although little bit short time pa...\n",
       "59999                                         satisfactory\n",
       "Name: lemmatized, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file = '../../data/data_processed.csv'\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "df[\"lemmatized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696885ff",
   "metadata": {},
   "source": [
    "### 2. BOW (Bag Of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b59dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after applying BOW : \n",
      "\n",
      "(r_idx, c_idx) cnt\n",
      "   (0, 111766)\t2\n",
      "  (0, 93232)\t1\n",
      "  (0, 18459)\t1\n",
      "  (0, 73802)\t1\n",
      "  (0, 102724)\t1\n",
      "  (0, 23720)\t1\n",
      "  (0, 21228)\t4\n",
      "  (0, 69802)\t1\n",
      "  (0, 87247)\t1\n",
      "  (0, 108772)\t1\n",
      "  (0, 121983)\t1\n",
      "  (0, 151580)\t1\n",
      "  (0, 137152)\t1\n",
      "  (0, 56392)\t1\n",
      "  (0, 53926)\t1\n",
      "  (0, 117945)\t1\n",
      "  (0, 71116)\t1\n",
      "  (0, 141438)\t1\n",
      "  (0, 161786)\t1\n",
      "  (0, 149304)\t1\n",
      "  (0, 59802)\t1\n",
      "  (0, 122389)\t2\n",
      "  (0, 148091)\t1\n",
      "  (0, 89693)\t1\n",
      "  (0, 21120)\t1\n",
      "  :\t:\n",
      "  (59998, 74989)\t1\n",
      "  (59998, 120467)\t1\n",
      "  (59998, 41807)\t1\n",
      "  (59998, 110160)\t1\n",
      "  (59998, 51525)\t1\n",
      "  (59998, 155548)\t1\n",
      "  (59998, 48228)\t2\n",
      "  (59998, 118037)\t1\n",
      "  (59998, 93025)\t1\n",
      "  (59998, 22867)\t1\n",
      "  (59998, 135274)\t1\n",
      "  (59998, 143298)\t1\n",
      "  (59998, 40705)\t1\n",
      "  (59998, 50413)\t1\n",
      "  (59998, 76348)\t1\n",
      "  (59998, 57940)\t1\n",
      "  (59998, 27002)\t1\n",
      "  (59998, 41551)\t1\n",
      "  (59998, 148687)\t1\n",
      "  (59998, 153127)\t1\n",
      "  (59998, 129722)\t1\n",
      "  (59998, 64625)\t1\n",
      "  (59998, 52948)\t1\n",
      "  (59998, 32060)\t1\n",
      "  (59999, 129715)\t1\n",
      "features : ['00' '000' '0000000000001' ... 'þór' 'יגאל' 'כרמון']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# counts the occurrences of each word.\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(df[\"lemmatized\"])\n",
    "print(\"after applying BOW : \\n\")\n",
    "print(\"(r_idx, c_idx) cnt\\n\",X_bow)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "print(\"features :\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c67702",
   "metadata": {},
   "source": [
    "### 3. Save BOW to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed557596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz(\"../../data/bow_features.npz\", X_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1462e02f",
   "metadata": {},
   "source": [
    "### 4. TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#with TF-IDF, its importance is reduced because it’s too common. Instead, rare words like \"awesome\" or \"disappointed\" may get higher scores.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "features_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=features_tfidf)\n",
    "\n",
    "tfidf_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
